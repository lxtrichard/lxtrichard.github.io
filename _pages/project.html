---
layout: archive
title: ""
permalink: /project/
author_profile: true
---

<html>
 <head></head>
 <body>
  <h1> Research Project </h1> 
  <hr style="width:100%;height:3px;background-color:#333;" /> 
  <table style="font-size:16px;border:none"> 
   <tbody>
    <tr height="200px"> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/project1.JPG" width="200px" /> </td> 
     <td style="border:none"> <b><font size="5.5">Weakly supervised segmentation on pelvic X-rays </font></b><br /> <b><i> Advisor: <a href="http://www.cad.zju.edu.cn/home/chenwei/" target="_blank" rel="noopener">Prof.Wei Chen</a> </i></b><br /> 1. Construct U-Net to attain ROIs of the femur<br /> 2. Utilize Dense161 Network to classify different types of bone fracture in femur<br /> 3. Propose an innovative weakly supervised segmentation method to complete fracture segmentation only based on text labels<br /> </td> 
    </tr> 
    <tr height="200px"> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/project2.JPG" width="220px" /> </td> 
     <td style="border:none"> <b><font size="5.5">Medical Image Segmentation</font></b><br /> <b><i> Advisor: <a href="http://www.cad.zju.edu.cn/home/chenwei/" target="_blank" rel="noopener">Prof.Wei Chen</a> </i></b><br /> 1.Launch structure combining ResNet and UNet, leveraging ResNet for down-sampling and UNet for upsampling, achieving a faster training time and a higher accuracy<br /> 2. Pioneer segment task completion on LUNA dataset through utilization of VNet architecture<br /> 3. Navigate preparation of dataset employing dense161 to classify fracture types<br /> </td> 
    </tr> 
    <tr height="200px"> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/project3.JPG" width="220px" /> </td> 
     <td style="border:none"> <b><font size="5.5"> Cell Structure Clustering and Visualization</font></b><br /> <b><i> Advisor: <a href="https://person.zju.edu.cn/en/nengganzheng" target="_blank" rel="noopener">Prof.Nenggan Zheng</a> </i></b><br /> 1. Evaluated and identified proper algorithms to execute clustering tasks on electron microscopic image<br /> 2. Achieved visualization of the cell structure with Davies-Bouldin performance of 0.85 on small samples<br /> 3. Learned the automated reconstruction of neuronal morphology based on local geometrical and global structural models<br /> </td> 
    </tr> 
   </tbody>
  </table> 
  <h1> Course Project </h1> 
  <hr style="width:100%;height:3px;background-color:#333;" /> 
  <table style="font-size:16px;border:none"> 
   <tbody>
    <tr height="300px"> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/cs194/final_project.gif" width="250px" /> </td> 
     <td style="border:none;;padding-left:40px"> <b><font size="5.5">CS 194-26 Final Project: Neural Style Transfer</font></b><br /> The works of Gatys et al. demonstrated the capability of Convolutional Neural Networks (CNNs) in creating artistic style images. This process of utilizing CNNs to transfer content images in different styles referred to as Neural Style Transfer (NST).<br /> In this work, we re-implement image-based NST, fast NST, arbitrary NST and human-to-anime face transfer. We also extend the algorithms to transfer daytime to night, mix different styles and create artistic style videos.<br /> <a href="https://inst.eecs.berkeley.edu/~cs194-26/sp20/upload/files/projFinalProposed/cs194-26-agr/" target="_blank">Website</a> <p></p><br /> </td> 
    </tr> 
    <tr> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/cs194/proj1.jpg" width="250px" /> </td> 
     <td style="border:none;;padding-left:40px"> <b><font size="5.5">Images of the Russian Empire</font></b><br /> We demonstrate a fully automated colorization approach for separating three color components and applying image processing and techniques to align them together and reproduce full-color images. <br /><a href="https://inst.eecs.berkeley.edu/~cs194-26/sp20/upload/files/proj1/cs194-26-agr/" target="_blank" rel="noopener">Website</a> <p></p><br /> </td> 
    </tr> 
    <tr> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/cs194/proj2.jpg" width="290px" /> </td> 
     <td style="border:none;;padding-left:40px"> <b><font size="5.5">Fun with Filters and Frequencies</font></b><br /> We implement gaussian filter and use it to straighten the image. We also blend different images together by utilizing the frequency. <br /><a href="https://inst.eecs.berkeley.edu/~cs194-26/sp20/upload/files/proj2/cs194-26-agr/" target="_blank" rel="noopener">Website</a> <p></p><br /> </td> 
    </tr> 
    <tr> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/cs194/proj3.gif" width="200px" /> </td> 
     <td style="border:none;;padding-left:40px"> <b><font size="5.5">Face Morphing</font></b><br /> We implement face warping with triangulations, produce a caricature of our face and make a music video. <br /><a href="https://inst.eecs.berkeley.edu/~cs194-26/sp20/upload/files/proj3/cs194-26-agr/" target="_blank" rel="noopener">Website</a> <p></p><br /> </td> 
    </tr> 
    <tr> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/cs194/proj4.jpg" width="280px" /> </td> 
     <td style="border:none;;padding-left:40px"> <b><font size="5.5">Classification and Segmentation</font></b><br /> First we complete a classification task by training a model on Fashion-mnist dataset. Then we construct a unet to implement semantic segmentation on the Facade dataset. In the end, we reach the top 5 accuracy in the class. <br /><a href="https://inst.eecs.berkeley.edu/~cs194-26/sp20/upload/files/proj4/cs194-26-agr/" target="_blank" rel="noopener">Website</a> <p></p><br /> </td> 
    </tr> 
    <tr> 
     <td width="250px" align="center" style="border:none"> <img src="/images/project/cs194/proj5.jpg" width="300px" /> </td> 
     <td style="border:none;;padding-left:40px"> <b><font size="5.5">[Auto]Stitching Photo Mosaics</font></b><br /> In the first part, we select the keypoints munually and blend three images together. In the second part, we implement ANMS, feature matching and RANSAC to automatically find the keypoints and blend the images into a panorama. <br /><a href="https://inst.eecs.berkeley.edu/~cs194-26/sp20/upload/files/proj5B/cs194-26-agr/" target="_blank" rel="noopener">Website</a> <p></p><br /> </td> 
    </tr> 
   </tbody>
  </table>
 </body>
</html>
